apiVersion: apps/v1
kind: Deployment
metadata:
  name: genai-python
  namespace: petclinic
  labels:
    app: genai-python
    tier: backend
    language: python
spec:
  replicas: 1
  selector:
    matchLabels:
      app: genai-python
  template:
    metadata:
      annotations:
        # OpenTelemetry Operator injection is DISABLED to avoid double instrumentation
        # The application uses built-in zero-code instrumentation via opentelemetry-instrument
        # All required environment variables (including K8s metadata) are configured below
      labels:
        app: genai-python
        tier: backend
        language: python
    spec:
      containers:
      - name: genai-python
        image: genai-python:latest
        imagePullPolicy: Never  # For local k3s, use local image
        # Use standard asyncio event loop instead of uvloop to fix context propagation
        command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8084", "--loop", "asyncio"]
        ports:
        - containerPort: 8084
          name: http
          protocol: TCP
        env:
        - name: CONFIG_SERVER_URL
          value: "http://config-server:8888"
        - name: EUREKA_SERVER_URL
          value: "http://discovery-server:8761/eureka"
        - name: CUSTOMERS_SERVICE_URL
          value: "http://customers-service:8081"
        - name: VETS_SERVICE_URL
          value: "http://vets-service:8083"
        # OpenAI Configuration (required for GenAI features)
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: genai-secrets
              key: openai-api-key
        - name: OPENAI_MODEL
          value: "gpt-4o-mini"
        
        # ========================================
        # OpenTelemetry Configuration for AI Agent Monitoring
        # ========================================
        
        # Service name (required for proper identification in APM)
        - name: OTEL_SERVICE_NAME
          value: "genai-python"
        
        # OTLP Exporter endpoint (Splunk OTel Collector)
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://splunk-otel-collector-agent.default.svc.cluster.local:4318"
        
        # OTLP Protocol (http/protobuf is the default, but making it explicit)
        - name: OTEL_EXPORTER_OTLP_PROTOCOL
          value: "http/protobuf"
        
        # Kubernetes environment information (via Downward API)
        - name: OTEL_RESOURCE_ATTRIBUTES_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: OTEL_RESOURCE_ATTRIBUTES_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: OTEL_NODE_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: OTEL_POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        
        # Resource attributes with K8s metadata (matching Operator behavior)
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: "service.namespace=petclinic,deployment.environment=o11y-custom-petclinic,k8s.container.name=genai-python,k8s.deployment.name=genai-python,k8s.namespace.name=petclinic,k8s.node.name=$(OTEL_RESOURCE_ATTRIBUTES_NODE_NAME),k8s.pod.name=$(OTEL_RESOURCE_ATTRIBUTES_POD_NAME),service.instance.id=petclinic.$(OTEL_RESOURCE_ATTRIBUTES_POD_NAME).genai-python,service.version=latest"
        
        # Trace context propagation (W3C TraceContext and Baggage)
        - name: OTEL_PROPAGATORS
          value: "tracecontext,baggage"
        
        # Splunk-specific profiler settings (matching Operator behavior)
        - name: SPLUNK_PROFILER_ENABLED
          value: "true"
        - name: SPLUNK_PROFILER_MEMORY_ENABLED
          value: "true"
        
        # Required: Metric temporality preference for OTLP exporter
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: "DELTA"
        
        # Specify exporters for each signal type
        - name: OTEL_TRACES_EXPORTER
          value: "otlp"
        - name: OTEL_METRICS_EXPORTER
          value: "otlp"
        - name: OTEL_LOGS_EXPORTER
          value: "otlp"
        
        # Enable Python logging auto-instrumentation for trace/span correlation
        - name: OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED
          value: "true"
        
        # ========================================
        # GenAI-specific instrumentation settings
        # Required for AI Agent Monitoring feature
        # ========================================
        
        # Capture LLM input/output content
        # WARNING: This captures sensitive data. Disable in production if needed.
        - name: OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT
          value: "true"
        
        # Where to emit captured content (both span attributes and events)
        - name: OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT_MODE
          value: "SPAN_AND_EVENT"
        
        # Enable Splunk-specific GenAI emitters
        # This enables AI Agent Monitoring in Splunk Observability Cloud
        - name: OTEL_INSTRUMENTATION_GENAI_EMITTERS
          value: "span_metric_event,splunk"
        
        # ========================================
        # GenAI Evaluation Settings (LLM-as-a-Judge)
        # Required for Splunk AI Agent Monitoring evaluations
        # ========================================
        
        # Condense evaluations into a single event (recommended for better visualization)
        - name: OTEL_INSTRUMENTATION_GENAI_EVALS_RESULTS_AGGREGATION
          value: "true"
        
        # Specify evaluation results category for Splunk visualization
        # This is CRITICAL for evaluation metrics to appear in Splunk APM
        - name: OTEL_INSTRUMENTATION_GENAI_EMITTERS_EVALUATION
          value: "replace-category:SplunkEvaluationResults"
        
        # Allow DeepEval to write temporary artifacts to filesystem
        # Note: Splunk documentation recommends READ_ONLY, but READ_WRITE is required
        # for full evaluation functionality in this deployment
        - name: DEEPEVAL_FILE_SYSTEM
          value: "READ_WRITE"
        
        # Sample rate for evaluations (1.0 = 100%, evaluate all spans)
        - name: OTEL_INSTRUMENTATION_GENAI_EVALUATION_SAMPLE_RATE
          value: "1.0"
        
        # Create detailed log for each evaluation result (useful for debugging)
        - name: OTEL_GENAI_EVAL_DEBUG_EACH
          value: "true"
        
        # Debug evaluation skips to understand why evaluations might not run
        - name: OTEL_GENAI_EVAL_DEBUG_SKIPS
          value: "true"
        
        # DeepEval timeout and retry configuration
        # Increase timeout for complex evaluations
        - name: DEEPEVAL_PER_ATTEMPT_TIMEOUT_SECONDS_OVERRIDE
          value: "300"
        
        # Retry failed evaluations up to 2 times
        - name: DEEPEVAL_RETRY_MAX_ATTEMPTS
          value: "2"
        
        # Disable DeepEval's own telemetry to avoid conflicts
        - name: DEEPEVAL_TELEMETRY_OPT_OUT
          value: "YES"
        
        # Azure OpenAI Configuration (alternative to OpenAI)
        # - name: AZURE_OPENAI_KEY
        #   valueFrom:
        #     secretKeyRef:
        #       name: genai-secrets
        #       key: azure-openai-key
        # - name: AZURE_OPENAI_ENDPOINT
        #   valueFrom:
        #     secretKeyRef:
        #       name: genai-secrets
        #       key: azure-openai-endpoint
        # - name: AZURE_OPENAI_DEPLOYMENT
        #   value: "gpt-4o"
        resources:
          limits:
            memory: "1Gi"
            cpu: "1"
          requests:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 8084
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        volumeMounts:
        - name: vectorstore
          mountPath: /app/vectorstore
      volumes:
      - name: vectorstore
        emptyDir: {}

